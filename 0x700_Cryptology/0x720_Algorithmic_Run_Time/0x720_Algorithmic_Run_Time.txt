Algorithmic un time is a bit different from the run time of a program
Since an algorithm is simply an idea, there's no limit to the processing speed for evaluating the algorithm
This means that an expression of algorithmic run time in minutes or seconds is meaningless

Without factors such as processor speed and architecture, the important unknown for an algorithm is input size
A sorting algorithm running on 1,000 elements will certainly take longer than the same sorting algorithm running on 10 elements
The input size is generally denoted by n, and each atomic step can be expressed as a number
The run time of a simple algorithm, such as the one that follows, can be expressed in terms of n
_________________________________________________________
for(i = 1 to n) {
   Do something;
   Do another thing;
}
Do one last thing;
_________________________________________________________

This algorithm loops n times, each time doing 2 actions, and then does 1 last action, so the time complexity for this algorithm would be 2n+1
A more complex algorithm with an additional nested loop tacked on, shown below, would have a time complexity of n^2+2n+1, since the new action is executed n^2 times
_________________________________________________________
for(x = 1 to n) {
   for(y = 1 to n) {
      Do the new action;
   }
}
for(i = 1 to n) {
   Do something;
   Do another thing;
}
Do one last thing;
_________________________________________________________

But this level of detail for time complexity is still too small
For example, as n becomes larger, the relative difference between 2n+5 and 2n+365 becomes less and less
However, as n becomes larger, the relative difference between 2n^2+5 and 2n+5 becomes larger and larger
This type of generalized trending is what is most important to the run time of an algorithm

Consider 2 algorithms, one with a time complexity of 2n+365 and the other with 2n^2+5
The 2n^2+5 algorithm will outperform the 2n+365 algorithm on small values for n
But for n = 30, both algorithms perform equally, and for all n greater than 30, the 2n+365 algorithm will outperform 2n^2+5 algorithm
Since there are only 30 values for n in which the 2n^2+5 algorithm performs better, but an infinite number of values for n in which the 2n+365 algorithm is generally more efficient

This means that, in general, the growth rate of the time complexity of an algorithm with respect to input size is more important than the time complexity for any fixed input
While this might not always hold true for specific real-world applications, this type of measurement of an algorithm's efficiency tends to be true when arranged over all possible applications